services:
  postgres:
    image: ankane/pgvector:latest
    container_name: researcher-postgres
    environment:
      POSTGRES_USER: researcher
      POSTGRES_PASSWORD: researcher_pass
      POSTGRES_DB: research_papers
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./services/vector-db/sql/init_pgvector.sql:/docker-entrypoint-initdb.d/init_pgvector.sql:ro
    healthcheck:
      # Check the configured database rather than relying on default DB name
      test: ["CMD-SHELL", "pg_isready -h 127.0.0.1 -p 5432 -d research_papers -U researcher"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: researcher-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  migrate:
    image: researcher-document-processing-service:latest
    build:
      context: ./services/document-processing
      dockerfile: Dockerfile
    container_name: migrate-service
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=migrate
    volumes:
      - ./services/document-processing:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    # Override the document-processing image entrypoint so this container ONLY runs migrations
    # and exits. Prevents uvicorn from starting inside the migrate job.
    entrypoint:
      - alembic
      - upgrade
      - head


  document-processing:
    image: researcher-document-processing-service:latest
    build:
      context: ./services/document-processing
      dockerfile: Dockerfile
    container_name: document-processing-service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=document-processing
    volumes:
      - ./services/document-processing:/app
      - ./uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  vector-db:
    image: researcher-vector-db-service:latest
    build:
      context: ./services/vector-db
      dockerfile: Dockerfile
    container_name: vector-db-service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=vector-db
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./services/vector-db:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase2
      - phase3
      - phase4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  llm-service:
    image: researcher-llm-service:latest
    build:
      context: ./services/llm-service
      dockerfile: Dockerfile
    container_name: llm-service
    ports:
      - "8003:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=llm-service
      - CUDA_VISIBLE_DEVICES=1  # Use second GPU (GTX 960) for local LLM inference
    volumes:
      - ./services/llm-service:/app
    depends_on:
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase3
      - phase4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  celery-worker:
    image: researcher-document-processing-service:latest
    build:
      context: ./services/document-processing
      dockerfile: Dockerfile
    container_name: celery-worker
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - VECTOR_DB_URL=http://vector-db:8000
      - SERVICE_NAME=celery-worker
    volumes:
      - ./services/document-processing:/app
      - ./uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    entrypoint: []
    command: celery -A celery_app worker --loglevel=info -Q document_processing,batch_processing,metadata_extraction,ocr_processing --concurrency=2
    profiles:
      - phase4

  flower:
    image: mher/flower:2.0.1
    container_name: flower-monitor
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - FLOWER_PORT=5555
    depends_on:
      redis:
        condition: service_healthy
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    profiles:
      - phase4

  api-gateway:
    image: researcher-api-gateway-service:latest
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    container_name: api-gateway-service
    ports:
      - "8000:8000"
    environment:
      - DOCUMENT_SERVICE_URL=http://document-processing:8000
      - VECTOR_SERVICE_URL=http://vector-db:8000
      - LLM_SERVICE_URL=http://llm-service:8000
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=api-gateway
      - ENVIRONMENT=development
      - DEBUG=true
      - CORS_ORIGINS=["http://localhost:3000","http://localhost:8000"]
    volumes:
      - ./services/api-gateway:/app
    depends_on:
      - document-processing
      - vector-db
      - llm-service
      - redis
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase4

volumes:
  postgres_data:
  redis_data:
#  uploads_data:
