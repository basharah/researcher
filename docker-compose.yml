services:
  postgres:
    image: ankane/pgvector:latest
    container_name: researcher-postgres
    environment:
      POSTGRES_USER: researcher
      POSTGRES_PASSWORD: researcher_pass
      POSTGRES_DB: research_papers
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./services/vector-db/sql/init_pgvector.sql:/docker-entrypoint-initdb.d/init_pgvector.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U researcher"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: researcher-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  document-processing:
    image: researcher-document-processing-service:latest
    build:
      context: ./services/document-processing
      dockerfile: Dockerfile
    container_name: document-processing-service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=document-processing
    volumes:
      - ./services/document-processing:/app
      - ./uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  vector-db:
    image: researcher-vector-db-service:latest
    build:
      context: ./services/vector-db
      dockerfile: Dockerfile
    container_name: vector-db-service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=vector-db
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./services/vector-db:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase2
      - phase3
      - phase4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  llm-service:
    image: researcher-llm-service:latest
    build:
      context: ./services/llm-service
      dockerfile: Dockerfile
    container_name: llm-service
    ports:
      - "8003:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=llm-service
      - CUDA_VISIBLE_DEVICES=1  # Use second GPU (GTX 960) for local LLM inference
    volumes:
      - ./services/llm-service:/app
    depends_on:
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase3
      - phase4
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  api-gateway:
    image: researcher-api-gateway-service:latest
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    container_name: api-gateway-service
    ports:
      - "8000:8000"
    environment:
      - DOCUMENT_SERVICE_URL=http://document-processing:8000
      - VECTOR_SERVICE_URL=http://vector-db:8000
      - LLM_SERVICE_URL=http://llm-service:8000
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=api-gateway
      - ENVIRONMENT=development
      - CORS_ORIGINS=["http://localhost:3000","http://localhost:8000"]
    volumes:
      - ./services/api-gateway:/app
    depends_on:
      - document-processing
      - vector-db
      - llm-service
      - redis
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    profiles:
      - phase4

volumes:
  postgres_data:
  redis_data:
#  uploads_data:
