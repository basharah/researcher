# Docker Compose - Production Optimized
# Use this for better performance and lower resource usage
# No auto-reload, optimized for production-like environment

services:
  postgres:
    image: ankane/pgvector:latest
    container_name: researcher-postgres
    environment:
      POSTGRES_USER: researcher
      POSTGRES_PASSWORD: researcher_pass
      POSTGRES_DB: research_papers
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./services/vector-db/sql/init_pgvector.sql:/docker-entrypoint-initdb.d/init_pgvector.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h 127.0.0.1 -p 5432 -d research_papers -U researcher"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G

  redis:
    image: redis:7-alpine
    container_name: researcher-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  migrate:
    image: researcher-document-processing-service:latest
    build:
      context: ./services/document-processing
      dockerfile: Dockerfile
    container_name: migrate-service
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=migrate
    volumes:
      - ./services/document-processing:/app
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    entrypoint:
      - alembic
      - upgrade
      - head

  document-processing:
    image: researcher-document-processing-service:latest
    container_name: document-processing-service
    user: "1000:1000"
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=document-processing
    volumes:
      - ./services/document-processing:/app:ro  # Read-only for better performance
      - uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M

  vector-db:
    image: researcher-vector-db-service:latest
    container_name: vector-db-service
    user: "1000:1000"
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=vector-db
      - CUDA_VISIBLE_DEVICES=-1  # Use CPU only to avoid GPU OOM
      - HF_HOME=/home/appuser/.cache/huggingface
    volumes:
      - ./services/vector-db:/app:ro  # Read-only
      - huggingface_cache:/home/appuser/.cache/huggingface  # Writable cache
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 512M
          # GPU disabled - using CPU to avoid OOM crashes

  llm-service:
    image: researcher-llm-service:latest
    container_name: llm-service
    user: "1000:1000"
    ports:
      - "8003:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REDIS_URL=redis://redis:6379
      - SERVICE_NAME=llm-service
      - CUDA_VISIBLE_DEVICES=1
    volumes:
      - ./services/llm-service:/app:ro  # Read-only
    depends_on:
      redis:
        condition: service_healthy
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  api-gateway:
    image: researcher-api-gateway-service:latest
    container_name: api-gateway-service
    user: "1000:1000"
    ports:
      - "8000:8000"
    environment:
      - DOCUMENT_SERVICE_URL=http://document-processing:8000
      - VECTOR_SERVICE_URL=http://vector-db:8000
      - LLM_SERVICE_URL=http://llm-service:8000
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - SERVICE_NAME=api-gateway
      - ENVIRONMENT=production
      - DEBUG=false
      - CORS_ORIGINS=["http://localhost:3000","http://localhost:8000"]
    volumes:
      - ./services/api-gateway:/app:ro  # Read-only
    depends_on:
      - document-processing
      - vector-db
      - llm-service
      - redis
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  celery-worker:
    image: researcher-document-processing-service:latest
    container_name: celery-worker-prod
    user: "1000:1000"
    environment:
      - DATABASE_URL=postgresql://researcher:researcher_pass@postgres:5432/research_papers
      - REDIS_URL=redis://redis:6379
      - VECTOR_DB_URL=http://vector-db:8000
      - SERVICE_NAME=celery-worker
    volumes:
      - ./services/document-processing:/app:ro  # Read-only
      - uploads_data:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
      vector-db:
        condition: service_started
    entrypoint: []
    command: celery -A celery_app worker --loglevel=info -Q document_processing,batch_processing,metadata_extraction,ocr_processing --concurrency=2
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M

  flower:
    image: mher/flower:2.0.1
    container_name: flower-monitor-prod
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
      - celery-worker
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

volumes:
  postgres_data:
  redis_data:
  uploads_data:
  huggingface_cache:
